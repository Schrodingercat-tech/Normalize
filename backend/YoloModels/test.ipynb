{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ImgHandle import responsePayload,ImageData\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "content = '../assects/images/city.jpg'\n",
    "with open(content,'rb') as f:\n",
    "    image = BytesIO(f.read())\n",
    "\n",
    "model = responsePayload(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 7 cars, 3 buss, 2 trucks, 65.3ms\n",
      "Speed: 2.7ms preprocess, 65.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 3 buss, 2 trucks, 62.6ms\n",
      "Speed: 3.0ms preprocess, 62.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 3 buss, 2 trucks, 71.1ms\n",
      "Speed: 4.0ms preprocess, 71.1ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 3 buss, 2 trucks, 60.6ms\n",
      "Speed: 2.0ms preprocess, 60.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 3 buss, 2 trucks, 81.9ms\n",
      "Speed: 3.0ms preprocess, 81.9ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 7 cars, 3 buss, 2 trucks, 70.2ms\n",
      "Speed: 2.5ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "crop = model.getCropObj('car',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.asarray(crop)\n",
    "bio = BytesIO()\n",
    "Image.fromarray(arr).save(bio,format='jpeg')\n",
    "bio.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BytesIO at 0x1333dbb3ba0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'responsePayload' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m objs_in_pic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mcrop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n\u001b[0;32m      2\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m nthobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'responsePayload' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "objs_in_pic = list(crop.keys())\n",
    "name = 'person'\n",
    "nthobj = 0\n",
    "if name in objs_in_pic:\n",
    "    images = crop[name]\n",
    "    no_of_images = len(images)\n",
    "    if 0<= nthobj <= no_of_images:\n",
    "        result = images[nthobj]\n",
    "    else : \n",
    "        result = {'response : ':f'there is no {nthobj} object in the {name} please provide the number from 0 to {no_of_images}'}\n",
    "else :\n",
    "    result = {'response : ':f'theres no {name} in the uploaded image please try to provide the names from {objs_in_pic}'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCropObj(self,objName:str,objIndex:int):\n",
    "        \"\"\"\n",
    "        returns the cropped object image\n",
    "        \"\"\"\n",
    "        found_objs = self.inImageObjects\n",
    "        objs_in_img = list(found_objs.keys())\n",
    "        obj_count_in_img = int(found_objs[objName])\n",
    "        if objName in objs_in_img:\n",
    "            if 0<=objIndex<=found_objs[objName]:\n",
    "                return self.imgCrop[objName][objIndex]\n",
    "            else : return {'response' : f'either passed invalid index or out of range',\n",
    "                           'object_count' : obj_count_in_img\n",
    "                           }\n",
    "        else : return {'response' : f'there are no objects in the image with name {objName}\\\n",
    "                        or not detected by the system\\\n",
    "                        please do check the keywords in the following {objs_in_img}',\n",
    "                       'detected_objects_in_image' : objs_in_img\n",
    "                       }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': 3, 'key2': 2, 'key3': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dict = {\n",
    "    'key1': [1, 2, 3],\n",
    "    'key2': [4, 5],\n",
    "    'key3': [6, 7, 8, 9]\n",
    "}\n",
    "\n",
    "# Use map to create a new dictionary with lengths instead of lists\n",
    "length_dict = dict(map(lambda item: (item[0], len(item[1])), original_dict.items()))\n",
    "\n",
    "{key : len(value) for key,value in original_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 7 cars, 3 buss, 2 trucks, 98.3ms\n",
      "Speed: 4.0ms preprocess, 98.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 7, 5.0: 3, 7.0: 2})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs = model.predict[0].boxes.data.numpy()[:,-1]\n",
    "Counter(objs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
